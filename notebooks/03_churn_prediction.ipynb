{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Churn Prediction\n",
        "\n",
        "This notebook builds and evaluates machine learning models for customer churn prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('')), '../src'))\n",
        "\n",
        "# Import modules\n",
        "from src.data_preprocessing import DataPreprocessor\n",
        "from src.churn_prediction import ChurnPredictor\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('viridis')\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data preprocessor\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# Load processed data\n",
        "df = preprocessor.load_processed_data('../data/processed/processed_data.csv')\n",
        "\n",
        "# Display first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare Data for Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for churn prediction\n",
        "X_train, X_test, y_train, y_test = preprocessor.split_data(df, 'Churn')\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Training set churn rate: {y_train.mean():.2%}\")\n",
        "print(f\"Test set churn rate: {y_test.mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize churn predictor\n",
        "churn_predictor = ChurnPredictor()\n",
        "\n",
        "# Train models\n",
        "model_results = churn_predictor.train_models(X_train, y_train)\n",
        "\n",
        "# Display model results\n",
        "results_df = pd.DataFrame(model_results).T\n",
        "print(\"Model Performance (Cross-Validation Accuracy):\")\n",
        "print(results_df)\n",
        "\n",
        "# Visualize model performance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=results_df.index, y='cv_mean', data=results_df)\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Cross-Validation Accuracy')\n",
        "plt.ylim(0.7, 1.0)\n",
        "\n",
        "# Add error bars\n",
        "plt.errorbar(x=results_df.index, y=results_df['cv_mean'], \n",
        "             yerr=results_df['cv_std'], fmt='none', c='black', capsize=5)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(results_df['cv_mean']):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../visualizations/model_comparison.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate best model on test set\n",
        "evaluation_metrics = churn_predictor.evaluate_model(X_test, y_test)\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(\"Evaluation Metrics:\")\n",
        "for metric, value in evaluation_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "feature_importance = churn_predictor.get_feature_importance(X_train)\n",
        "\n",
        "if feature_importance is not None:\n",
        "    # Display top 10 important features\n",
        "    print(\"Top 10 Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "    # Visualize feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='importance', y='feature', data=feature_importance.head(15))\n",
        "    plt.title('Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../visualizations/feature_importance.png', dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimize the best model\n",
        "optimization_results = churn_predictor.optimize_model(X_train, y_train)\n",
        "\n",
        "if optimization_results:\n",
        "    print(\"Optimization Results:\")\n",
        "    print(f\"Best parameters: {optimization_results['best_params']}\")\n",
        "    print(f\"Best cross-validation score: {optimization_results['best_score']:.4f}\")\n",
        "\n",
        "    # Evaluate optimized model\n",
        "    optimized_metrics = churn_predictor.evaluate_model(X_test, y_test)\n",
        "\n",
        "    print(\"\\nOptimized Model Evaluation Metrics:\")\n",
        "    for metric, value in optimized_metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Compare with original model\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Original': evaluation_metrics,\n",
        "        'Optimized': optimized_metrics\n",
        "    })\n",
        "\n",
        "    print(\"\\nModel Comparison:\")\n",
        "    print(comparison_df)\n",
        "\n",
        "    # Visualize comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    comparison_df.plot(kind='bar')\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.ylabel('Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Model')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('../visualizations/model_optimization.png', dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Predict on New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the entire dataset\n",
        "churn_predictions, churn_probabilities = churn_predictor.predict_churn(df.drop(columns=['Churn', 'CustomerID']))\n",
        "\n",
        "# Add predictions to the original data\n",
        "df_with_predictions = df.copy()\n",
        "df_with_predictions['Churn_Prediction'] = churn_predictions\n",
        "df_with_predictions['Churn_Probability'] = churn_probabilities\n",
        "\n",
        "# Display first few rows with predictions\n",
        "print(\"Data with Churn Predictions:\")\n",
        "print(df_with_predictions[['CustomerID', 'Churn', 'Churn_Prediction', 'Churn_Probability']].head(10))\n",
        "\n",
        "# Analyze prediction accuracy\n",
        "accuracy = (df_with_predictions['Churn'] == df_with_predictions['Churn_Prediction']).mean()\n",
        "print(f\"\\nPrediction accuracy on full dataset: {accuracy:.2%}\")\n",
        "\n",
        "# Analyze prediction distribution\n",
        "prediction_counts = df_with_predictions['Churn_Prediction'].value_counts()\n",
        "print(\"\\nPrediction Distribution:\")\n",
        "print(prediction_counts)\n",
        "\n",
        "# Visualize prediction distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='Churn_Prediction', data=df_with_predictions)\n",
        "plt.title('Prediction Distribution')\n",
        "plt.xlabel('Predicted Churn (0=No, 1=Yes)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Add percentage labels\n",
        "total = len(df_with_predictions)\n",
        "for p in plt.gca().patches:\n",
        "    height = p.get_height()\n",
        "    plt.gca().text(p.get_x() + p.get_width()/2., height + 50,\n",
        "                    f'{height/total*100:.1f}%',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../visualizations/prediction_distribution.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "churn_predictor.save_model('../models/churn_model.pkl')\n",
        "\n",
        "# Save data with predictions\n",
        "df_with_predictions.to_csv('../data/processed/data_with_predictions.csv', index=False)\n",
        "\n",
        "print(\"Model and predictions saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary\n",
        "\n",
        "This notebook built and evaluated machine learning models for customer churn prediction. Key findings:\n",
        "\n",
        "1. Trained multiple models with Random Forest performing best\n",
        "2. Achieved high accuracy in predicting customer churn\n",
        "3. Identified key features that influence churn\n",
        "4. Model optimization improved performance\n",
        "5. Made predictions on the entire dataset\n",
        "\n",
        "Next steps:\n",
        "- Generate business insights and recommendations\n",
        "- Develop targeted retention strategies\n",
        "- Create a deployment pipeline for the model"
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  }
}